\section{Methods}
\label{sec:methods}


Our methodology is based on the implementation of a complete data cycle
to enhance model predictions in a coastal ocean domain through robotic
adaptive sampling and data assimilation. The approach consists of three
fundamental steps, executed iteratively on a daily basis:

\begin{description}

\item[Model Forecast and Uncertainty Projection]: A numerical ocean
  model provides a daily one-step forecast $\hat{\theta}(k+1, x, y)$
  of a target oceanic variable $\theta$, along with an associated
  uncertainty field $\sigma_{\hat{\theta}}(k+1, x, y)$, where $k$
  represents the current day and $(x, y)$ denote the geographical
  coordinates.  These outputs are organized into discrete spatial
  maps, $M_{\hat{\theta}}(x, y)$ and
  $M_{\sigma_{\hat{\theta}}}(x, y)$, representing, respectively, the
  predicted state and its uncertainty over a predefined grid covering
  the study area. 

\item \textbf{Target Sample Planning}: Using the uncertainty map
  $M_{\sigma_{\hat{\theta}}}(x, y)$ as input, a targeted sampling
  algorithm determines the set of trajectories for a fleet of $N$ AUVs
  for the next operational cycle. The goal is to maximize the
  accumulated uncertainty sampled along the vehicle paths, while
  satisfying vehicle-specific constraints. The planned trajectories
  are transmitted to the vehicles for execution.

\item \textbf{Data Collection and Assimilation}: Throughout the
  operational period, each AUV collects measurements of the target
  variable $\theta$ along its assigned path. After the mission is
  completed, the collected measurements are assimilated into the
  numerical model using an appropriate data assimilation scheme. This
  updated model state serves as the new initial condition for the next
  forecasting cycle, closing the loop.

\end{description}

While previous efforts have concentrated on a form on embedded
automated decision-making on AUVs
\cite{mcgann08a,mcgann08b,ryan10,py10,Das-2010-637,das10,olaya12,rajan12}
to demonstrate adaptive sampling, here we AUV trajectories are defined
by human-in-the-loop decisions apriori, with adaptation focused on
deployment based on $M_{\sigma_{\hat{\theta}}}(x, y)$. No automated
decisions were made on the AUVs. Loop closure in this work, refers to
the \emph{sample-assimilate-predict-direct} process as shown in
Fig. \ref{fig:loop-closure}.

\subsection{Model Forecast, Uncertainty Projection and Data Assimilation}

Sampling strategies rely on timely information about the spatial
variability of ocean properties. However, conventional numerical ocean
models are computationally intensive, and their runtime makes them
impractical for use in near-real-time mission planning \kcomment{Need
  a citation here}. While similar assimilation cycles could, in
principle, be implemented directly within deterministic numerical
models, this would require either substantially higher computational
resources or larger temporal horizons.


As a more practical alternative, we employ geostatistical stochastic
sequential simulation as a computationally efficient surrogate,
producing short-term spatial predictions of ocean variables together
with estimates of spatial uncertainty \cite{deutsch1992}. This
approach captures the essential variability of local ocean dynamics,
based on calibrated deterministic dynamic ocean models, at a fraction
of the computational cost of numerical models, while remaining
flexible enough to rapidly assimilate new in situ observations
\cite{Duarte2025}.  However, with this type of surrogate models we are
not explicitly considering the full-physics of the ecosystem and the
quality of the predictions directly depends on the accuracy of the
calibrated model. If the calibrated model is unable to capture the
true nature of the system the geostatistical predictions will likely
be inaccurate.  Equally, if there is a new oceanographic event that is
not present in the calibrated model, the geostatistical approach will
not be captured.

The I SUGGEST BEING MORE SPECIIC ABOUT THE METHODOLOGY - WHICH METHODOLOGY» methodology relies on ensembles of geostatistical realizations,
each representing a WHAT DO WE MEAN BY STATE OF THE OCEAN state of the ocean ELIMINATE TEMPERATURE temperature field conditioned
by \emph{a priori} deterministic ocean models \cite{CMEMS2017} and
direct observations. By computing the pointwise standard deviation
across the ensemble, we obtain spatial uncertainty maps that highlight
regions where predictions are \sout{less constrained} more variable
and therefore potentially more informative for sampling. These maps
serve as the basis for identifying areas where new measurements are
expected to maximize the reduction of forecast error.

Beyond uncertainty prediction, the proposed framework also allows
direct assimilation of AUV acquired data CUT THE REST PF THE SENTENCE? during oceanographic
campaigns. Data collected on a given day are used to update the ocean
ELIMINATE TEMPERATURE temperature forecast for the following day by combining prior
predictions with new measurements. The simulation grid, in this case,
includes two temporal layers: the first containing the AUV
measurements at their spatial locations and the second corresponding
to the new prediction step. With AUV sampling denser than the grid
resolution, measurements within the same grid cell are averaged as a
form of arithmetic upscaling \cite{Duarte2025}. To incorporate spatial
and temporal variability, we apply direct sequential simulation with
local means \cite{soares2001direct}, where each simulated value is
drawn from its conditional distribution, accounting for both prior
simulated values and local mean models. This enables consistent
updating of the ELIMINATE TEMPERATURE temperature field while integrating both direct AUV
observations and \textit{priori} information. The ensemble of
realizations thus provides an updated ocean forecast and a
quantitative measure of uncertainty.\kcomment{I think this para is
  very important and should be clear. An image of the process would be
  very helpful}
%%
 
WHICH EXAMPLE? Example shown here, REPETEAD ABOVE the geostatistical realizations are produced using
direct sequential simulation \cite{soares2001direct}, a stochastic
method that draws values from conditional probability distributions END OF REPEATED ABOVE 
defined by SUGGEST ADDING THIS PHRASE TO TEXT ABOVE kriging estimates and variances and conditioned to existing
direct measurements and a spatial covariance matrix. The continuity of
the TEMPERATTURE? temperature field in space and time is characterized by variogram
models fitted to long-term calibrated ocean model data from
E.U. Copernicus Marine Service (CMS) \cite{CMEMS2017}. FOR INSTEAD OF AT? At each depth
of the numerical ocean model, geostatistical simulations are carried
out independently, using a moving temporal window of fourteen previous
days as conditioning data (i.e., experimental data) to predict the
subsequent day. The size of the temporal window was achieved by
trial-and-error using a calibrated numerical model for the same region
and under the same season, and comparing the geostatistical
predictions against the response of numerical ocean mode. This
sliding-window strategy strikes a balance between forecast skill and
computational feasibility, and can be adapted according to the
complexity of the oceanographic conditions. AN EXPLANATION OF THE METHOD THAT PROCEEDS BY DEPTHS MAY BE USEFUL . iS PROPAGRATION DONE ONLY IN THE HORIZONTAL DOMAINS?

ELIMINATE THIS PHASE IT IS MENTIONED ABOVE The ensemble of realizations provides both a forecast of ocean
TEMPERATURE? temperature and a quantitative assessment of the prediction
uncertainty.  By updating the forecasts with new AUV measurements
through sequential assimilation, the method progressively refines the
TEMPERATURE temperature field while maintaining consistency with prior model
dynamics. ELMINATE THIS SENTENCE The resulting forecasts and uncertainty maps form the input
for the target sampling algorithm, guiding the allocation of AUV
trajectories towards regions of greatest expected information
gain. More details about the model, its development, and application
during the \proj experiment can be found in \cite{Duarte2025}. WHY NO ELIMINATING THIS PARAGRAPH EXCEPT FOR THE LAST SENTENCE?

DOES IT MAKE SENSE TO ELIMINATE TARGET IN THE TITLE?

\subsection{Target Sampling Algorithm}

The adaptive sampling problem here is posed as the design of vehicle
trajectories that maximize information gain
\cite{eidsvik2015,fossum18} extracted from a model-derived uncertainty
map, while satisfying operational AUV constraints. Each day, the
models provide both a forecast field and its associated uncertainty
distribution, which together define the reward landscape for the
planner. The task is then to generate, for each vehicle, a CLOSED PATH, A TOUR, ERASE composed of waypoints END OF ERASE that accumulates the highest possible
uncertainty values. THE TOUR IS TRAVELED AT A PRESCRIBED SPEED WHILE THE DURATION IS BOUNDED ABOVE BY THE ASSIMILATION PERIOD. THE STARTING AND ENDING POINT IS SELECTED TO SIMPLIFY LOGISTICS FOR LAUNCH AND RECOVERY.

IT MAY BE WORTH SAYING MORE ABOUT THESE PARAMETERS: DURATION OF THE TOUR, ASSIMILATION PERIOD, ETC.

To address this, the problem is cast as a graph theoretic problem. The
spatial uncertainty map is first pre-processed to remove obstacles and
smoothened to highlight large-scale features. Candidate waypoints are
then identified from the map and used to build a weighted graph, where
nodes carry a reward proportional to their uncertainty value and edges
represent travel costs. The trajectory planning task is posed as a
vehicle TOUR routing problem where routes must balance the rewards obtained
from visiting nodes with associated costs of traveling between them
\cite{vidal2013,toth2014vehicle}. By solving this, the algorithm
returns a set of near-optimal trajectories that prioritize regions of
greatest uncertainty, while ensuring vehicle endurance and safety
constraints. This provides a principled way of steering autonomous
platforms toward the most informative sampling locations, forming a
key component in the daily cycle of forecast, adaptive sampling, and
data assimilation. Additional insights into the algorithm and its
deployment during \proj are reported elsewhere in
\cite{bernacchi2025}.

TITLE: SHOULD IT BE OPERATIONS AND DATA COLLECTION INSTEAD?
\subsection{Data Collection, Deployment and Operations}


\begin{figure}
    \centering
    \includegraphics[width=.7\linewidth]{fig/lauvs.png}
    \caption{AUVs deployed in the \proj experiment.}
    \label{fig:lauvs}
\end{figure}

In-situ data collection process involved three upper water-column Light Autonomous Underwater Vehicles (LAUV)
(XP2, XP3 and XP5) which PERFORMED ERASE alternated daily in performing ENDERASE targeted
sampling missions STARTNEW with durations of up to 60 hours  ENDNEW over the \naz Canyon region. These vehicles designed
and developed in-house at the University of Porto \cite{sousa2012lauv}
came equipped with a range of sensors including a CTD
(Fig. \ref{fig:lauvs}). sTARTERASE Some had in addition fluorometers, turbidity,
Oxygen, DVL/ADCP sensors ENDERASE and with WiFi and Iridium
satellite communications; the CTDs mounted on the AUVs were cross-calibrated to
ensure consistency. In addition to the hardware involved, an extensive
suite of mature mission planning and command/control tools were used
-- discussion of these is outside the scope of the paper and can be
referenced at
\cite{dias2005neptus,seacons10,toolchain2012,pinto2013lsts,Ferreira2018}.


IT MAY BE WORTH USING AN ABRIDGED VERSION OF THE PARAGRAPH BELOW TO
EXPLAIN A FEW DETAILS OF THE OPERATION OTHERWISE PEOPLE MAY NOT
UNDERSTAND WHAT WAS REALLY DONE

SOMETHING LIKE

Launch and recovery of AUV operations was done with the support of two
small boats rented in Nazaré, thus minimizing the logistics
footprint. In addition, to the LSTS command and control center located
in Porto, another center was installed in Nazaré to support local
operations.


Challenging meteorological and ocean conditions constrained the team
from multiple iterations of the
\emph{sample-assimilate-predict-direct} loop to a three-day sequence
of consecutive experiments (29-–31 October, 2025)
(Fig. \ref{fig:scheme}). The analysis in this work aims to quantify
the impact of assimilating AUV-acquired temperature data on the
predictive performance of the statistical model and to assess the
operational feasibility of the data cycle approach in a real-world
coastal setting. To simply the process the model's workflow and the
assimilation loop was focused only towards temperature data. As a
consequence this work is univariate in showing the impact of
assimilated model-driven exploration. We believe that results in Sec
\ref{sec:results} are general enough to apply to other critical
oceanographic variables which would need to be modeled similarly.


Each experimental day followed a structured cycle involving: (i) the
generation of a statistical model forecast and its associated
uncertainty field based on the Copernicus Marine Service (CMS)
\cite{sotillo2021} data available up to the previous day; (ii) the
execution of the target sampling algorithm to plan the next-day
missions; and (iii) in situ data collection by AUVs following the
algorithmically determined transects. The data collected within the
previous day were subsequently assimilated into the statistical model
to produce updated forecasts, enabling comparisons between forecasts
with and without data assimilation.


\begin{figure}
    \centering
    \includegraphics[scale=0.12]{fig/scheme.png}
    \caption{Three-day sequence
      (29\textsuperscript{th}–31\textsuperscript{st} October 2025) of
      the sample–assimilate–predict–direct loop in \proj. Each cycle
      integrates CMS-based statistic model prediction, target sampling
      algorithm, LAUV temperature data acuisition and subsequent
      assimilation for the next day prediction}
    \label{fig:scheme}
\end{figure}

On 29\textsuperscript{th} October, the statistical model produced the
initial forecast solution (A), which was used to plan the mission
executed by XP2. The resulting in situ temperature data were later
assimilated offline to produce an updated statistical model solution
(B1) for 30 October. Although operational real-time assimilation was
initially planned, logistical constraints prevented its
implementation. Consequently, all assimilation cases were performed
offline after mission completion. The target sampling algorithm,
therefore, relied on statistical forecasts without assimilation (B),
using pre-existing data as input for daily mission planning. This
limitation is not expected to have significantly affected the
experimental outcomes, as the operational area was spatially compact
and the predicted variability field remained consistent between
consecutive days. In future implementations, on-board or
near-real-time assimilation should be considered to fully exploit the
adaptive potential of the framework.

Data collected by XP3 and XP5 on 30 October were assimilated offline
to generate new model solutions for 31 October (C1, C2, C3, C4), along
with a non-assimilated reference case (C). The configurations were as
follows:

\begin{itemize}
    \item C1 – assimilation including only XP2 data from 29 October;
    \item C2 – assimilation including XP2 (29 October) and XP5 (30 October) data;
    \item C3 – assimilation including only XP5 data from 30 October;
    \item C4 – assimilation including all available data from 29 and
      30 October (XP2, XP3, and XP5).
\end{itemize}

An analogous setup was used for scenario D, in which the difference
from case C is that the statistical predictions for 31 October were
generated using CMS data available as prior up to different cutoff dates:

\begin{itemize}
\item D – forecast for 31 October based on CMS data available as prior
  until 29 October;
    \item D1–D4 – corresponding to the same assimilation
      configurations as C1–C4, but using CMS data available as prior until 30
      October.
\end{itemize}

Model performance was evaluated by comparing predicted and observed
temperature data along the AUV trajectories using the root-mean-square
error (RMSE) as the primary performance metric for 31 October.

\begin{figure}
    \centering
    %\includegraphics[width=.7\linewidth]{fig/temperatureprofiles.png}
    \caption{INSERT schematic about the 3-day loop}
    \label{fig:temperatureprofiles}
\end{figure}

