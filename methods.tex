
\section{Methods}
% max 3000 words

Our methodology is based on the implementation of a complete data cycle to enhance model predictions in a coastal ocean domain through adaptive sampling and data assimilation. The approach consists of three fundamental steps, executed iteratively on a daily basis:

\begin{enumerate}
    \item \textbf{Model Forecast and Uncertainty Projection}:  
    A numerical ocean model provides a daily one-step forecast $\hat{\theta}(k+1, x, y)$ of a target oceanic variable $\theta$, along with an associated uncertainty field $\sigma_{\hat{\theta}}(k+1, x, y)$, where $k$ represents the current day and $(x, y)$ denote the geographical coordinates. These outputs are organized into discrete spatial maps, $M_{\hat{\theta}}(x, y)$ and $M_{\sigma_{\hat{\theta}}}(x, y)$, representing, respectively, the predicted state and its uncertainty over a predefined grid covering the study area.
    
    \item \textbf{Target Sampling Planning}:  
    Using the uncertainty map $M_{\sigma_{\hat{\theta}}}(x, y)$ as input, an target sampling algorithm determines the set of trajectories for a fleet of $N$ Autonomous Underwater Vehicles (AUVs) for the next operational cycle. The goal is to maximize the accumulated uncertainty sampled along the vehicle paths, while satisfying vehicle-specific constraints such as maximum endurance, operational limits, and navigation feasibility. The planned trajectories are transmitted to the vehicles for execution.

    \item \textbf{Data Collection and Assimilation}:  
    Throughout the operational period, each AUV collects pointwise measurements of the target variable $\theta$ along its assigned path. After the mission is completed, the collected measurements are assimilated into the numerical model using an appropriate data assimilation scheme. This updated model state serves as the new initial condition for the next forecasting cycle, closing the loop.
\end{enumerate}

\subsection{Model Forecast and Uncertainty Projection}
Sampling strategies rely on timely information about the spatial variability of ocean properties. However, conventional numerical ocean models are computationally intensive, and their runtime makes them impractical for use in near-real-time mission planning. While similar assimilation cycles could in principle be implemented directly within deterministic numerical models, this would require either substantially higher computational resources or larger temporal horizons. As a more practical alternative, we employ geostatistical simulation as a computationally efficient surrogate, producing short-term predictions of ocean temperature together with estimates of uncertainty \cite{deutsch1992}. This approach captures the essential variability of local ocean dynamics at a fraction of the cost of full numerical models, while remaining flexible enough to assimilate new in situ observations quickly \cite{Duarte2025} and coherent with the scope of the work approach.

The methodology relies on ensembles of geostatistical realizations, each representing a state of the ocean temperature field conditioned by a priori deterministic ocean models \cite{CMEMS2017} and direct observations (FRESNEL fieldwork). By computing the pointwise standard deviation across the ensemble, we obtain spatial uncertainty maps that highlight regions where predictions are less constrained and potentially more informative for sampling. These maps serve as the basis for identifying areas where new measurements are expected to maximize the reduction of forecast error \cite{Duarte2025}.   

Geostatistical realizations are produced using direct sequential simulation \cite{soares2001direct}, a stochastic method that draws values from conditional probability distributions defined by kriging estimates and variances. The continuity of the temperature field in space and time is characterized by variogram models fitted to long-term calibrated ocean model data \cite{CMEMS2017}. At each depth, simulations are carried out independently, using a moving temporal window of fourteen previous days to predict the subsequent day. This sliding-window strategy strikes a balance between forecast skill and computational feasibility, and can be adapted according to the complexity of the oceanographic conditions.

The ensemble of realisations provides both a forecast of ocean temperature and a quantitative assessment of the prediction uncertainty. By updating the forecasts with new AUV measurements through sequential assimilation, the method progressively refines the temperature field while maintaining consistency with prior model dynamics. The resulting forecasts and uncertainty maps form the input for the target sampling algorithm, guiding the allocation of AUV trajectories towards regions of greatest expected information gain. More details about the model, its development, and application during the FRESNEL campaign can be found in \cite{Duarte2025}.

\subsection{Target Sampling Algorithm}

The adaptive sampling problem is formulated as the design of vehicle trajectories that maximize the amount of useful information extracted from a model-derived uncertainty map, while respecting the endurance and safety constraints of the fleet. Each day, the models provide both a forecast field and its associated uncertainty distribution, which together define the reward landscape for the planner. The task is then to generate, for each vehicle, a path composed of waypoints that accumulates the highest possible uncertainty values, subject to limits on distance, time, and operational feasibility.

To address this, the problem is cast in graph form. The spatial uncertainty map is first pre-processed to remove obstacles and smoothed to highlight large-scale features. Candidate waypoints are then identified from the map and used to build a weighted graph, where nodes carry a reward proportional to their uncertainty value and edges represent travel costs. The trajectory planning task is posed as a Prize Collecting Vehicle Routing Problem (PCVRP)\cite{vidal2013,toth2014vehicle}, a well-known formulation in combinatorial optimization where routes must balance the rewards obtained from visiting nodes with the costs of traveling between them.

By solving this problem, the algorithm returns a set of near-optimal trajectories that prioritize regions of greatest uncertainty, while ensuring vehicle endurance and safety constraints are respected. This provides a principled way of steering autonomous platforms toward the most informative sampling locations, forming a key component in the daily cycle of forecast, adaptive sampling, and data assimilation.

Additional insights into the algorithm formulation and its deployment during FRESNEL are reported in \cite{bernacchi2025}.

\subsection{Available Models}
\subsection{Adaptive Sampling Algorithm}
\subsection{Available robotic systems and assets}

% The adaptive sampling problem is formulated as an optimization task aiming to maximize the expected information gain from the observations. Specifically, given the predicted uncertainty map and operational constraints (e.g., time, energy budget), the algorithm plans vehicle routes that prioritize areas of higher model uncertainty. The uncertainty along each candidate path is evaluated, and path planning strategies — such as greedy heuristics or combinatorial optimization techniques — are employed to allocate waypoints efficiently among the available AUVs.

\subsection{Operational Constraints and Practical Considerations}

% The practical implementation of the data cycle in a real-world marine environment introduces several constraints:

% \begin{itemize}
%     \item \textbf{Communication Limitations}:  
%     Low-bandwidth and intermittent communications at sea require that mission planning be sufficiently robust to accommodate long periods of autonomous operation without human intervention.
    
%     \item \textbf{Vehicle Constraints}:  
%     AUV endurance, payload limitations, navigation precision, and deployment risks all impose restrictions on the feasible operational space and mission duration.

%     \item \textbf{Computational Demands}:  
%     Real-time generation of uncertainty fields, optimization of paths, and assimilation of collected data must be performed within time windows compatible with daily operational cycles, often under constrained computational resources.

%     \item \textbf{Environmental Variability}:  
%     Fast-evolving coastal ocean dynamics can introduce discrepancies between forecasted and actual conditions, necessitating robust planning that accounts for forecast uncertainty and adaptivity.
% \end{itemize}

% This method was deployed and evaluated under the operational framework of the FRESNEL project, providing a real-world demonstration of the data cycle’s feasibility and benefits in complex coastal environments.


% Distinction Between Onboard and Offboard Predictions:
% \begin{itemize}
%     \item Onboard: Statistical prediction
%     \item Offboard: Numerical prediction
% \end{itemize}

% Rationale and Implementation (including a schematic figure):
% \begin{itemize}
%     \item Why this approach?
%     \item How was it executed?
% \end{itemize}

% Adaptive Sampling Strategy:
% \begin{itemize}
%     \item contraints
%     \item Algorithm used for real-time decision-making
%     \item Criteria for data collection optimization
% \end{itemize}

% Statistical Approach:
% \begin{itemize}
%     \item Techniques applied for uncertainty estimation
%     \item Integration with observational data
% \end{itemize}

%  Numerical Model (HOPS - Harvard Ocean Prediction System):
% \begin{itemize}
%     \item Model configuration and setup
%     \item Data assimilation methods
% \end{itemize}


